
\begin{figure}
  \centering
  \begin{subfigure}{.2\linewidth}
    \lstinputlisting[style=refinity]{ObjectCreation/REFINITY/before.refinity}
    \caption{Before}
  \end{subfigure}\hspace{1cm}
  \begin{subfigure}{.2\linewidth}
    \lstinputlisting[style=refinity]{ObjectCreation/REFINITY/after.refinity}
    \caption{After}
  \end{subfigure}
\captionof{lstlisting}{Object creation}
\label{lst:ObjectCreation-refinity}
\end{figure}

As we have seen in the previous section, \Refinity{} encodes a rather harsh regimen on program equivalence:
in the absence of a more fine-grained (application-specific) post-condition, it encodes that return values or exceptions must be identical on both sides,
as must be the objects in the \relevant{} location set (and the observables in this location set must be adequately specified).

This, in combination with the symbolic execution of both programs, create a hurdle for programs that contain object creations (and, subsequently exceptions).
An object allocation in JavaDL is, roughly sketched, symbolically executed by creating a fresh function symbol for the allocated object and storing it on the symbolic heap.


The question of equivalence for created objects is not specific to abstract execution, yet important for its practicability: 
abstract statements are embedded in concrete programs which change as well, and more complex and application specific refactorings must all language features of the
host language into account.


At its core, the challenge lies in the fact that, as both programs are executed in the same proof, all objects created within them are not equal to each other: it is not possible to prove that the program \lstinline[style=refinity]|return new C();| is equivalent to itself.
Indeed, it is not obvious whether the program should be considered equivalent to itself in the first place.
The program is executed twice from the same state, but this does not suffice for the two created objects to be equal -- the allocation must, additionally, be deterministic.
In the following we make the assumption that this is indeed the case and use this information in the symbolic execution as follows.

\begin{definition}
We assume that in every state of the Kripke structure, for every heap $h$, all objects are ordered by some order $<_h$, such that there is some
object $o_h$, such that (1) for all $o' <_h o_h$ the object $o'$ is allocated (i.e., its \codein{<allocated>} field is set to true), and
(2) for all $o_h \leq_h o''$ the object $o''$ is not allocated. 
We introduce a unary function symbol \codein{allocate} with the signature $\mathtt{Heap} \rightarrow \mathtt{Object}$,
whose interpretation must adhere to $\mathcal{I}(\mathtt{allocate})(h) = o_h$. The (slightly prettified) rule is as follows:

\begin{prooftree}
\AxiomC{$\Gamma,\{U\}(\mathtt{v} \not\doteq \mathtt{null} \wedge \mathtt{v} \doteq \mathtt{allocate(heap)} \wedge \mathtt{C::exactInstance(v)}\doteq\mathtt{TRUE})$}
\noLine
\UnaryInfC{$\hspace{50mm}\Rightarrow \{U\}\{\mathtt{heap} := \mathtt{create(heap, v)}\}[\mathtt{s}]\phi, \Delta$}
\UnaryInfC{$\Gamma \Rightarrow \{U\}[ \mathtt{v~=~C.allocate();~s}]\phi, \Delta$}
\end{prooftree}


%\begin{figure}
%allocateInstance {    
%\find (==> \modality{#allmodal}{.#pm@#t2().. #lhs = #t.#allocate()@#t; ...}\endmodality(post))
%}\varcond(\hasSort(#t2, alphaObj))
%\replacewith (==> {heap := create(heap,#lhs)}
%)                \modality{#allmodal}{..  ...}\endmodality(post))
%\add(#lhs != null
%& (wellFormed(heap) -> boolean::select(heap, #lhs, java.lang.Object::<created>) = FALSE)
%& (alphaObj::allocate(heap) = #lhs)
%& alphaObj::exactInstance(#lhs) = TRUE ==>)
%\heuristics(method_expand)
%};
%\end{figure}

\end{definition}
The modification is the addition of $v = \mathtt{allocate(heap)}$ to the antecedent.\footnote{In terms of implementation, the modification is changing the \texttt{allocateInstance} taclet in KeY.}
The modified rule suffices to show the simple equivalence of \codein{return new C()} to itself from above.
Continuing our investigation of when objects are considered equal, 
where the two allocations are independent from each other, i.e., any side-effects of the constructors are not visible to each other, \codein{C} is not a subtype of \codein{D} and vice versa.
Again the question where the two \codein{C} (resp.\ \codein{D}) objects are equal arises.
They are not equal in the sense that, if there is a global implicit\footnote{The counter is indeed implicit, as the order $<_h$ cannot be accessed by the proof system.} counter
that counts all allocation, they get the same number from this counter. They are equal in the sense that there is no explicit way to distinguish them in the program.

They are, however, distinguishable in the proof system due to the term-representation of the heap.
If we choose to consider them equal, we must adapt our \codein{allocate} mechanism:
First, it must be able to distinguish between the allocation of different classes and, second, it must be able to simplify the heap to ignore irrelevant operations on it.
%\vsnote{@EK: on the one hand I agree, on the other, the way I see it, it's not that we want to ignore something, but we want the implicit partial order of independent changes? Anyway, no action required, and ignoring achieves this.}
\begin{definition}
We assume that in every state of the Kripke structure, for every heap $h$ and every class $C$, all objects of type $C$ are ordered by some order $<_h^C$, such that there is some
object $o_h^C$, such that (1) for all $o' <^C_h o$ the object $o'$ is allocated (i.e., its \codein{<allocated>} field is set to true), and
(2) for all $o \leq_h^C o''$ the object $o''$ is not allocated. Additionally, if $D$ is a subtype of $C$ then $<_h^D$ must be a suborder of $<_h^C$.
For each class $C$, we introduce a unary function symbol \codein{C::allocate} with the signature $\mathtt{Heap} \rightarrow \mathtt{Object}$,
whose interpretation must adhere to $\mathcal{I}(C::\mathtt{allocate})(h) = o_h^C$. The (slightly prettified) rule is as follows:

\begin{prooftree}
\AxiomC{$\Gamma,\{U\}(\mathtt{v} \not\doteq \mathtt{null} \wedge \mathtt{v} \doteq \mathtt{C::allocate(heap)} \wedge \mathtt{C::exactInstance(v)}\doteq\mathtt{TRUE})$}
\noLine
\UnaryInfC{$\hspace{50mm}\Rightarrow \{U\}\{\mathtt{heap} := \mathtt{create(heap, v)}\}[\mathtt{s}]\phi, \Delta$}
\UnaryInfC{$\Gamma \Rightarrow \{U\}[ \mathtt{v~=~C.allocate();~s}]\phi, \Delta$}
\end{prooftree}
Additionally, we give two simplification rules for heaps within any \codein{allocate} function application.
Let $\sqsubseteq$ be the subtype relation and $T(t)$ the type of a term.
\begin{align*}
\mathtt{C::allocate(store(h, o, f, v))}\rightsquigarrow\mathtt{C::allocate(h)}& &&\text{if $f \neq$ \codein{<allocated>}}\\
\mathtt{C::allocate(create(h, o))}\rightsquigarrow\mathtt{C::allocate(h)}& &&\text{if $C \not\sqsubseteq T(o)$}
\end{align*}
\end{definition}
The first rule uses the assumption that the orders are only sensitive to the \codein{<allocated>} field and the second one that they are independent, besides the subtyping relation.
Intuitively, this implements a different counter for each class in the type hierarchy and two objects are considered equal if the counters of their classes are equal.
Creating an object of a class, increases the counter of this class and all its superclasses.
This suffices to prove the programs in Listing~\ref{lst:ObjectCreation-refinity} to be equivalent. If~\codein{C} is a sub type of~\codein{D}, then the proof fails.
\vsnote*{Still not seeing how this can be true.}{%
The second rule is able to remove intermittent operations that are symbolically represented on the heap, e.g.\ in \lstinline{x = new C(); x.set(1); y = new D()} versus \lstinline{y = new D(); x = new C(); x.set(1)}, but are not relevant to object creation.
}

\begin{figure}[tbp]
\centering
\begin{subfigure}[b]{.3\linewidth}
\begin{lstlisting}[style=refinity]
class C {
  private int j;
  public C(int j){
    this.j = j;
  }
}
\end{lstlisting}
\caption{Class}
\end{subfigure}\hspace{3mm}
\begin{subfigure}[b]{.3\linewidth}
\begin{lstlisting}[style=refinity]
return new C(1);
\end{lstlisting}
\caption{Before}
\end{subfigure}\hspace{3mm}
\begin{subfigure}[b]{.3\linewidth}
\begin{lstlisting}[style=refinity]
return new C(2);
\end{lstlisting}
    \caption{After}
  \end{subfigure}
\captionof{lstlisting}{Object creation}
\label{lst:ObjectCreation-refinity-2}
\end{figure}

Note that we ignore the state of fields in the heap, meaning that equivalence of two objects is determined only by their counters. 
This requires to be careful with specification: it does not suffice for each notion of equivalence to specify that two objects are equal, but also \emph{their} fields must be equal.
For example, consider the class and programs in Listing~\ref{lst:ObjectCreation-refinity-2}.
The returned objects are identical, but in the post states the heap assigns different values to their field.
%To weaken the assumption and take the whole into account to determine  \vsnote*{@EK}{incomplete sentence}.

%both programs are equivalent, yet cannot be proved automatically due to syntactically different heaps.
%To address this limitation, we need additional rules that allow ignoring heap updates that are irrelevant.
%Surprisingly, the extant literature does not provide much automation there, but rather builds on restrictive specifications wrt.\ \assignable{}/\accessible{} frames.

%Coming back to our example, it is syntactically obvious that both sides yield different heaps.
%Before addressing the underlying problem, \vsnote{@Eduard: Let's skip the obvious that KeY didn't know that two objects allocated in identical heaps are hence identical, or?}
%we can immediately contribute a small taclet that states that two objects are identical, if their arguments to the constructor are equal and if any heap updates between the two allocations do not afffect the allocation of the second object.
%Similar to KeY's \keyrule{dropUpdate_2}, we can easily eliminate these operations on the heap on unrelated \textit{types} and obtain equivalent programs.
%\vsnote*{TODO: Eduard to elaborate a bit here.}{Unrelated types are of course only a shortcut, dropUpdate2 is much more specific, VS thinks -- but I can't decode the side conditions on the rule}.

Let us close with three remarks. First, the solutions we described here are enabling the programmer (or refactoring designer) to fine tune their notion of equivalence, which must be specified additionally to the refactoring itself.
Realizing the choice, however, is rather simple by enabling and disabling rules, resp.\ taclets. 
\eknote*{Changed}{Thus, we avoid to put even more burden on the first-order specification of the relational post-condition, and merely require the programmer to select from a number of options.
We stress that the taclets for the different options are not \emph{unsound}, but merely switch between different version of assumption about the (in this case underspecified) Java object model.}
%\vsnote{VERY interesting point, I completely disagree! Maybe what you're saying is that adding potentially unsound/not capturing taclets is easier than formulating an adequate post-condition? Having unsound taclets is the only reason I can see for disabling them -- that any strategy-search could be misguided is a different issue.}

Second, while we only discussed object creation here, the same solution also handles \emph{exceptions}, which must be created before being thrown. 
Exceptions are special in the sense that they have access to the program beyond the parts that are exposed to (non-reflective) programs.
For example, they can access the line number of the throwing statement for their stack trace.
%Thus, to consider two thrown exceptions equivalent, one may want \vsnote*{}{a complete sentence}.
As the stack trace is not modeled in JavaDL, its treatment for verification is an open research question in itself, and because we consider exhibiting the stack trace
within the program a dubious practice in the first place, we chose to ignore it in this paper.
%\vsnote{Agreed.}

Third, one could argue that we have not so much proven the refactoring to be correct,
but rather moved this decision further down the chain: unlike in a full formalization of the Java object model from ground up, 
we do not have a way of proving the taclets correct (i.e.\ derive them as lemmas) within KeY, as they model our assumptions about object identity when running two Java programs in the exact same state, which is not described by the Java semantics.

%\paragraph{Abstract Object Allocation Sites.}
%As discussed, the above solutions interact with abstract execution only indirectly by providing techniques to handle equivalences in the program surrounding the abstract statements and abstract expressions. 

\paragraph*{Excursus: Dead Code Elimination}
Similar considerations of equivalent heap manipulations need to be considered also in the are of optimizations, whose soundness proofs rely on relation verification as well.
Take for example the program in Listing~\ref{lst:xisnewxisnew}.
\begin{figure}
  \centering
  \begin{subfigure}[b]{.2\linewidth}
    \lstinputlisting[style=refinity]{DeadCode/Java/before.java}
    \caption{Before}
  \end{subfigure}\hspace{1cm}
  \begin{subfigure}[b]{.2\linewidth}
    \lstinputlisting[style=refinity]{DeadCode/Java/after.java}
    \caption{After}
  \end{subfigure}
\captionof{lstlisting}{Dead Object}
\label{lst:xisnewxisnew}
\end{figure}

Again, we assume that the constructor of \codein{C} has no side-effects (except object creation) upon constructor invocation.
In this case, the first object creation is of no consequence.
The additional rules above however will not yet be sufficient to prove that this version is equivalent to the version without the redundant object creation and assignment.
The location-set mechanism would still insist that the second object created  in the redundant version is a different object from the first (and only) object created in the optimized version.
On the one hand this can be addressed through a relaxed post-condition where we accept that we only need \textit{an} object of the right type and arguments, but it relies on the side-condition of the constructor not having side-effects, which requires a very restrictive method contract for the constructor.
Alternatively, the notion of equivalence becomes even more specification-heavy for optimizations, as it may be more fine-grained. 
%We face the same issue if we would want to encode the absence of side-effects as precondition to a taclet.

%%% Local Variables:
%%% mode: latex
%%% TeX-master: "main"
%%% eval: (auto-fill-mode -1)
%%% End:
